{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30fcaa84-6dd6-42f9-b3b4-ba1d43793e21",
   "metadata": {},
   "source": [
    "### Assignment\n",
    "#### Choose a dataset\n",
    "You get to decide which dataset you want to work on. The data set must be different from the ones used in previous homeworks You can work on a problem from your job, or something you are interested in. You may also obtain a dataset from sites such as Kaggle, Data.Gov, Census Bureau, USGS or other open data portals. \n",
    "Select one of the methodologies studied in weeks 1-10, and another methodology from weeks 11-15 to apply in the new dataset selected.\n",
    "\n",
    "#### To complete this task:. \n",
    "    - Describe the problem you are trying to solve.\n",
    "    - Describe your dataset and what you did to prepare the data for analysis. \n",
    "    - Methodologies you used for analyzing the data\n",
    "    - What's the purpose of the analysis performed\n",
    "    - Make your conclusions from your analysis. Please be sure to address the business impact (it could be of any domain) of your solution.\n",
    "    \n",
    "#### Deliverable\n",
    "Your final presentation (essay or video) should include:\n",
    "- The traditional R file or Python file and essay,\n",
    "- An Essay (minimum 500 word document) or Video ( 5 to 8 minutes recording)\n",
    "- Include the execution and explanation of your code. The video can be recorded on any platform of your choice (Youtube, Free Cam)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754c9b9-32d2-41ef-a2ee-28494aada3ed",
   "metadata": {},
   "source": [
    "# -----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391bb5c-2017-4dee-adfc-7ec31b10d240",
   "metadata": {},
   "source": [
    "## Overview\n",
    "For this assignment I decided to leverage my capstone project to also cover the rquirments for this DATA 622 Final Project. Therefore, while this file attempts to place everythign needed into one coherent file, the brightspace submission will have several additional files / links in order to provide full context if needed. The dataset used in the final analysis is one that was custom builts from a variety of publically available datasets, as well as using multiple different enrichment techniques. In short, this document is a condensed version of my capstone project to submit for DATA 622 Assignment 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d98159b-4d03-4e15-8f82-a0428c8ce8a8",
   "metadata": {},
   "source": [
    "## The Problem\n",
    "There has been a lot of research into the presence of urban trees on the surrounding environment, specifcially on their impacts on countering extreme heat and cold. Specifically, urban trees have been found to damper the effects of extreme head through providing shade and as a result of evapotranspiration. Additionally, there have been findings that outline how the presence of trees can help block wind, which tends to damper the impacts of extreme cold as well. As weather extremes become increasingly common due to climate change, further study on the impact of urban trees is needed. Specifically, in different regions in order to better understand how trees can help different cities. For this project, data specific to New York City was used in order to help identify any potential impact trees can have on energy use intensity in buildings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ed1f58-e2d8-4fbc-834e-6182566cae95",
   "metadata": {},
   "source": [
    "## Preparing the Data\n",
    "This project uses a custom built dataset derived from a multitude of different public datasets and resources. In short there were three main phases of gathering, enriching and processing data in order to distill the final working dataset. \n",
    "\n",
    "#### Part 1 - Buildings Data & Energy Usage (BuildingWork_Part1.ipynb)\n",
    "The first section of the data made use of Local Law 84 energy benchmarking data, which was is ingested via the NYC Open Data Socrata API for all years availabe, but ultimately was restricted to 2010 and 2017. This restriction was done to align with the primary second data source, which was the tree canopy change data. The main feature of interest in the Local Law 84 data was the \"weather normalized eui\" information, which is the energy usage intensity for each building that reports data normalized to counter weather variations between years. The raw data included a large number of administrative and reporting fields, ehich needed to be sifted through and dropped. The data was filtered in order to keep observations that are metered at the whole-building or whole-property level, while allowing some metering fields to remain null, as these fields were introduced in later reporting years.The buildings that were kept for this analysis, included those that were predominatly residential properties. The identifying dimensions of buildings, like unique identifiers (e.g., BBL, property id, addresses) were enriched using various methods like self-joining and publi APIs. Further more, these identifyincg columns, once properly enriched, were used in order to geocode each building to obtain a latitide/longitude point where the raw data had nulls. These geographic points were used in order to further add to the data with census tracts, building footprint geographies, and other spatially oriented data. Additional building information, such as Number of floors, zoning classifications, construction year, etc. were added to the data via the MapPLUTO API. Lastly, LiDAR-derived canopy change data that classifies the city into areas of canopy gain, loss, or no change between 2010 and 2017 was injested, and subsequently joined to the building data in order to cateogorize each building into one of those canopy categories. A buffer space of 50 feet was used, in order to limit any shifts in canopy coverage to within 50 feet of a building's footprint geometry. The final data set from this section limited to buildings that intersected (with the 50 foot buffer considered) with the canopy data for analysis. \n",
    "\n",
    "#### Part 2 - Tree Count Data (TreeWork_Part2.ipynb)\n",
    "The second section of processing focued on city-level forestry and tree data. As another tree-focused dataset, NYC street tree inventory data and forestry work order data from NYC Open Data were also ingested and processed. The data was filtered to keep only trees plausibly present during the 2010â€“2017 period. Newly planted trees that appear only very late in the series are dropped as too young to have a meaningful effect on shading or wind, while dead trees, stumps, and records with unusable coordinates are removed entirely. Finally, forestery work orders data, which is another tree focused dataset, was used to find and flag tree removals yielding a shift in tree inventory between 2010 and 2017. The yielded data is an attempt at a tree count for NYC in 2010 and 2017, two years that are outside of that \"NYC Tree Census\" years.  \n",
    "\n",
    "#### Part 3 - Putting it Together & Aggregation (Analysis_Part3.ipynb)\n",
    "The third and final steps to the data preparation and processing phase, is where the Part 1 data and the Part 2 data are put together into a final product. Essentially, using a spatial join, the tree counts were joined to the building data. Similar to the canopy data any tree that was wihtin 50 feet of a building geometric footprint was included in the data. In short, this step allow for the aggregation of a tree count for each building wthin the dataset to help with impact analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f106649d-cf08-47fb-8e8e-43a46ffb1886",
   "metadata": {},
   "source": [
    "## Data Analysis and Modeling\n",
    "The work outlined in the \"Preparing the Data\" section above was carried out in multiple different scripts, however for the purposes of this assignment, the analysis code is below, and the finalzied working dataset is just read in from CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7def213-a8f2-4be2-9bf3-b7d33cdcda68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b92d99-c899-4dd6-b137-be2534c5e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Reading in the Data \n",
    "df = pd.read_csv(\"FinalWorkingData_20251207.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b95d97d-7d16-4b85-91a9-078543c0bc26",
   "metadata": {},
   "source": [
    "#### Exploratory Analysis Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8bb0be-ff91-4dc0-9d59-35ab6eaefd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"mint_cream\": \"#F1F7ED\",\n",
    "    \"dark_slate_grey\": \"#243E36\",\n",
    "    \"muted_teal\": \"#7CA982\",\n",
    "    \"frosted_mint\": \"#E0EEC6\",\n",
    "    \"old_gold\": \"#C2A83E\",\n",
    "}\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "\n",
    "canopy_palette = {\n",
    "    \"Gain\": colors[\"muted_teal\"],\n",
    "    \"Loss\": colors[\"old_gold\"],\n",
    "    \"No Change\": colors[\"dark_slate_grey\"]\n",
    "}\n",
    "\n",
    "# Choropleth colormap (buildings per tract)\n",
    "bldg_cmap = LinearSegmentedColormap.from_list(\n",
    "    \"bldg_cmap\",\n",
    "    [colors[\"mint_cream\"], colors[\"muted_teal\"],]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f55d134-512c-4ccd-b7bc-a1b3b988b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CT2010 from NYC Open Data as GeoJSON\n",
    "CT2010_URL = \"https://data.cityofnewyork.us/resource/bmjq-373p.geojson?$limit=50000\"\n",
    "resp = requests.get(CT2010_URL, timeout=60)\n",
    "resp.raise_for_status()\n",
    "\n",
    "# Read into GeoDataFrame and project to EPSG:2263\n",
    "ct2010 = gpd.read_file(io.BytesIO(resp.content)).to_crs(2263)\n",
    "\n",
    "# Quick look\n",
    "ct2010.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0b76a7-e185-488a-a57c-5189aab0ffbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

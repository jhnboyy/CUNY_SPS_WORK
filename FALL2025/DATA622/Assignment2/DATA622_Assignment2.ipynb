{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7095360a-15b6-45dc-a563-235ca483d421",
   "metadata": {},
   "source": [
    "# DATA622 -  Assignment 2\n",
    "## Experimentation & Model Training\n",
    "\n",
    "### Introduction\n",
    "In Machine Learning, Experimentation refers to the systematic process of designing, executing, and analyzing different configurations to identify the optimal settings that performs best on a given task. Experimentation is learning by doing. It involves systematically changing parameters, evaluating results with metrics, and comparing different approaches to find the best solution; essentially, it's the practice of testing and refining machine learning models through controlled experiments to improve their performance.\n",
    "\n",
    "The key is to modify only one or a few variables at a time to isolate the impact of each change and understand its effect on model performance. In the assignment you will conduct at least 6 experiments. In real life, data scientists run anywhere from a dozen to hundreds of experiments (depending on the dataset and problem domain). \n",
    "\n",
    "### Assignment\n",
    "This assignment consists of conducting at least two (2) experiments for different algorithms: Decision Trees, Random Forest and Adaboost. That is, at least six (6) experiments in total (3 algorithms x 2 experiments each). For each experiment you will define what you are trying to achieve (before each run), conduct the experiment, and at the end you will review how your experiment went. These experiments will allow you to compare algorithms and choose the optimal model. \n",
    "\n",
    "Using the dataset and EDA from the previous assignment, perform the following: \n",
    "#### Algorithm Selection\n",
    "You will perform experiments using the following algorithms:\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Adaboost\n",
    "\n",
    "#### Experiment \n",
    "For each of the algorithms (above), perform at least two (2) experiments. In a typical experiment you should:\n",
    "- Define the objective of the experiment (hypothesis)\n",
    "- Decide what will change, and what will stay the same\n",
    "- Select the evaluation metric (what you want to measure)\n",
    "- Perform the experiment\n",
    "- Document the experiment so you compare results (track progress)\n",
    "    \n",
    "#### Variations\n",
    "There are many things you can vary between experiments, here are some examples:\n",
    "- Data sampling  (feature selection)\n",
    "- Data augmentation e.g., regularization, normalization, scaling\n",
    "- Hyperparameter optimization (you decide, random search, grid search, etc.)\n",
    "- Decision Tree breadth & depth (this is an example of a hyperparameter)\n",
    "- Evaluation metrics e.g., Accuracy, precision, recall, F1-score, AUC-ROC\n",
    "- Cross-validation strategy e.g., holdout, k-fold, leave-one-out\n",
    "- Number of trees (for ensemble models)\n",
    "- Train-test split: Using different data splits to assess model generalization ability\n",
    "\n",
    "#### Deliverable\n",
    "##### Essay (minimum 500 words)\n",
    "- Format: PDF\n",
    "- Write a short essay summarizing your findings. Your essay should include:\n",
    "    - Explain why you chose the experiments you did\n",
    "    - Discuss bias & variance across the experiments e.g., between Decision Tree experiments, and with Random Forest & Adaboost\n",
    "    - A table with experiments & results\n",
    "    - What was the optimal model you found, and why\n",
    "    - What conclusion did you came to? What do you recommend.\n",
    "- Code\n",
    "    - This should include your code, as well as the outputs of your code e.g. correlation chart\n",
    "    - Format: Code should be saved in https://rpubs.com or https://github.com. Please provide a link to your code repo in the submission.\n",
    "    - Please do not submit your code via Google Colab (due to permissioning issues)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557389e4-38c2-49a6-aad9-4a6c5dbb8e91",
   "metadata": {},
   "source": [
    "### Start of Assignment 2 Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9d465a7-0f18-4b46-aaef-2d29c34cdc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import json\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e03443f0-4f06-469e-a45a-7b56674ff3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pulling in the data from Assignment 1 \n",
    "df = pd.read_csv(\"raw_df_dropped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d28180-ccdd-45a2-8ee0-c72c04b7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns # No duration because dropped in assignment one. (Data Leakage) \n",
    "\n",
    "## Encoding the y var for (1/0) | (yes/no)\n",
    "df['y'] = df['y'].map({'no':0, 'yes':1})\n",
    "\n",
    "## Parsing the 'y' from the x vars \n",
    "X = df.drop(columns='y')\n",
    "y = df['y']\n",
    "\n",
    "## Splitting the test and train sets for future experiments and modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Confirming no nulls; no additional imputation needed because of Assignment 1 cleaning etc. \n",
    "# X_train.info()\n",
    "# y_train.info()\n",
    "# X_test.info()\n",
    "# y_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dca3aa3-18b9-4d5d-9f89-94a2292046db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'day_of_week', 'campaign', 'previous']\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'previously_contacted']\n"
     ]
    }
   ],
   "source": [
    "# Getting lists of the x vars and their types For encoding pre-modeling \n",
    "num_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "print(num_cols)\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f94fd95-9929-4ab5-a3a3-2ed9cb6bc540",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = pd.get_dummies(X_train, columns=cat_cols, drop_first=False)\n",
    "X_test_encoded  = pd.get_dummies(X_test,  columns=cat_cols, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b99212-6cc7-4076-ac1e-4f7afa487bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in X_train_encoded.columns if i not in X_test_encoded.columns])\n",
    "print([i for i in X_test_encoded.columns if i not in X_train_encoded.columns])\n",
    "## Columns are identical, no missing categories in each df so no need for alignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9de02b84-1062-4f70-bb89-16144216386f",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36908b-7520-4823-8864-0b444f65b6d2",
   "metadata": {},
   "source": [
    "### Beginning Experiments\n",
    "- Keeping the training and test the same through out, i want to get more of a sense for how each model works with the same data.\n",
    "- The primary metrics i will be watching over these experiements will be PR-AUC and the False Negatives. False negatives are missed clients, and the PR-AUC \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe11c5-56b6-4038-aa3e-7f5b1afdd21c",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "#### Experiment 1 \n",
    "**GOAL:** Using the decision tree classifier default inputs in orderto just carry out a baseline decision tree model for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c15efe-d7f0-4acd-b8b3-41d4e40eb6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.89      0.90      7833\n",
      "           1       0.29      0.33      0.31      1051\n",
      "\n",
      "    accuracy                           0.82      8884\n",
      "   macro avg       0.60      0.61      0.60      8884\n",
      "weighted avg       0.84      0.82      0.83      8884\n",
      "\n",
      "Accuracy Score\n",
      "0.8246285457001351\n",
      "ROC-AUC : 0.6106\n",
      "PR-AUC  : 0.1746\n",
      "TP: 347 FP: 854 FN: 704 TN: 6979\n"
     ]
    }
   ],
   "source": [
    "## Default settigns for baseline so threshoold is 0.5\n",
    "dec_tree1 = DecisionTreeClassifier(random_state=42)\n",
    "dec_tree1.fit(X_train_encoded, y_train)\n",
    "prob1 = dec_tree1.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = dec_tree1.predict(X_test_encoded)\n",
    "\n",
    "## Depth \n",
    "print(dec_tree1.tree_.max_depth)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, prob1), 4))        \n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, prob1), 4)) \n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"dec_tree1\":{\n",
    "        \"prob\":prob1,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b26b2-eeba-4bb8-9b09-e156a3d8c5ee",
   "metadata": {},
   "source": [
    "**Notes on Baseline Decision Tree Experiment 1:** \n",
    " - it seems that the \"no\" predicitons perform super well, while the \"yes\" values do not. This goes fir precision, recall, and f1 score. However this is most likely because of the imbalanced nature of the training and test data. Essentially no values are much more prominant then yes values.\n",
    " - When the DT model predics a yes value it is only correct 30% of time, it also misses a lot of the actual yes values. This is not a good model. \n",
    " - I think in experiment 2 we need to add balanced weights to the yes values in order to obtain better results.\n",
    " - The Macro Average, where wieghts and imbalances are considered is very different from the othern umbers. We need to tweak the weightings.\n",
    " - ROC_AUC is just slightly better than 50/50 chance; similarly the PR_AUC is just slightly better than the actual ratios\n",
    " - The False Positives in the confusion matrix are very high, we want to reduce this number.\n",
    " - The False Negatives are also very high. We want to reduce this. \n",
    " - For next experiment we want to change the settings so that the imbalance yes and no valueas are considered. Also, maybe limit the length of the deepest tree to stop overfitting and improve generalizations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adffc1c-0ab9-47d7-9d84-f2e27e35b9dc",
   "metadata": {},
   "source": [
    "#### Experiment 2\n",
    "**GOAL:** Now that we have a baseline performancewith the default settings of the decision tree model, We want to change the input settings to improve the model. The max depth of the tree will be limited to 10. as it went over 40 in the first one. Additionally, the min sample leaves will be set to 15 to prevent small splits. Also, adding the balance wiehgts because of the yes vs no ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "999cba63-303f-4928-9bb9-6f03964a0334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxDepth\n",
      "10\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89      7833\n",
      "           1       0.35      0.59      0.44      1051\n",
      "\n",
      "    accuracy                           0.82      8884\n",
      "   macro avg       0.64      0.72      0.67      8884\n",
      "weighted avg       0.87      0.82      0.84      8884\n",
      "\n",
      "Accuracy Score\n",
      "0.8208014407924359\n",
      "ROC-AUC : 0.7744\n",
      "PR-AUC  : 0.404\n",
      "TP: 624 FP: 1165 FN: 427 TN: 6668\n"
     ]
    }
   ],
   "source": [
    "dec_tree2 = DecisionTreeClassifier(\n",
    "    # LImiting the depth of the tree, with the baseline the depth was 42, way too deep. \n",
    "    max_depth=10,\n",
    "    # Kepping the leaves larger, small leaves will be prone to over fitting the model\n",
    "    min_samples_leaf=15,\n",
    "    ### Helping balacne the weights for the minority \"yes\" values for more accurate results.\n",
    "    class_weight='balanced',  \n",
    "    # Reproducibility.\n",
    "    random_state=42)      \n",
    "dec_tree2.fit(X_train_encoded, y_train)\n",
    "prob2 = dec_tree2.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = dec_tree2.predict(X_test_encoded)\n",
    "\n",
    "\n",
    "## Depth \n",
    "print(\"maxDepth\")\n",
    "print(dec_tree2.tree_.max_depth)\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, prob2), 4))        \n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, prob2), 4)) \n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"dec_tree2\":{\n",
    "        \"prob\":prob2,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2cd34f-46c7-45cf-b57b-24ef2970cb77",
   "metadata": {},
   "source": [
    "**Notes on Baseline Decision Tree Experiment 2:**\n",
    "-  The confusion matrix results have improved. The True Positives increased. However the False Positives Also increased, which is what we dont want. That being said the False negatives decreased which is good.\n",
    "-  The precision numbers didnt move too much, but the amount that they moved was in the proper direction. Secondly, the recall score increased a substaintial amount, so the model finds 2/3s of actual yes values. These shifts give a better F1 score.\n",
    "-  For the AUC values, the ROC-AOC increased which indicates a better perfromance, as did the PR-AUC.\n",
    "-  OVERALL: BETTER THAN DT EXPERIMENT 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005d2e72-67dc-4f39-9413-8077e2fd96fc",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "#### Experiment 1\n",
    "**GOAL:** Using the random forest model type, i want to again establish a baseline of performance for the first experiment for this model. Using default input settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "379404e2-a921-4f6a-b3af-c80793ba586a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94      7833\n",
      "           1       0.60      0.24      0.34      1051\n",
      "\n",
      "    accuracy                           0.89      8884\n",
      "   macro avg       0.75      0.61      0.64      8884\n",
      "weighted avg       0.87      0.89      0.87      8884\n",
      "\n",
      "Accuracy Score\n",
      "0.8912651958577218\n",
      "ROC-AUC : 0.7861\n",
      "PR-AUC  : 0.4239\n",
      "TP: 253 FP: 168 FN: 798 TN: 7665\n",
      "Tree depth — min: 33 mean: 38.08 max: 51\n",
      "Leaves — min: 5234 mean: 5400.9 max: 5571\n"
     ]
    }
   ],
   "source": [
    "rand_forest1 = RandomForestClassifier(random_state=42)\n",
    "rand_forest1.fit(X_train_encoded, y_train)\n",
    "rf_prob1 = rand_forest1.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = rand_forest1.predict(X_test_encoded)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, rf_prob1), 4))        \n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, rf_prob1), 4)) \n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "# depths of all trees\n",
    "depths = [est.tree_.max_depth for est in rand_forest1.estimators_]\n",
    "print(\"Tree depth — min:\", min(depths), \"mean:\", round(np.mean(depths), 2), \"max:\", max(depths))\n",
    "\n",
    "# number of leaves (optional)\n",
    "leaves = [est.get_n_leaves() for est in rand_forest1.estimators_]\n",
    "print(\"Leaves — min:\", min(leaves), \"mean:\", round(np.mean(leaves), 1), \"max:\", max(leaves))\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"rand_forest1\":{\n",
    "        \"prob\":rf_prob1,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423b99ff-2711-4346-b9c8-d6badc078536",
   "metadata": {},
   "source": [
    "**Random Forest Experiment 1 Notes:**\n",
    "- As a baseline the random forest results, with default inputs, performed better than the initial decision tree baseline. This shows up specifically in the AUC numbers, which is expected because of the methodology shift. \n",
    "- This margin of better performance was most relevant for the precision of the model, not the recall. Becayse of the recall scores, the F1 scroe is very similar to that of the baseline decision tree scores.\n",
    "- When looking at the confusion matrics the TP are actually worse than the Decision tree baseline. That also goes for the FN and the FP too. This may just be becuase the depth of the trees in the first DT model was overfitting to the data.\n",
    "- OVERALL: BETTER THAN DT 2 EXPERIMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7acadc6-1f74-484b-8bd9-7c69d8d7d5f8",
   "metadata": {},
   "source": [
    "##### Experiment 2\n",
    "**GOAL:** Improve upon the baseline default settings of the random forest technique with this data set. We will shift the inputs in order to get a better result. Will be limiting the depth fo the trees to prevent over fitting, also will be adding the weights for the yes/no ration imbalance. Were also going to mandate 5 samples minimum befor splitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a114a201-c055-43da-9192-181ebc86553a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      7833\n",
      "           1       0.50      0.41      0.45      1051\n",
      "\n",
      "    accuracy                           0.88      8884\n",
      "   macro avg       0.71      0.68      0.69      8884\n",
      "weighted avg       0.87      0.88      0.88      8884\n",
      "\n",
      "Accuracy Score\n",
      "0.8811346240432237\n",
      "ROC-AUC : 0.7958\n",
      "PR-AUC  : 0.435\n",
      "TP: 435 FP: 440 FN: 616 TN: 7393\n",
      "Tree depth — min: 20 mean: 20.0 max: 20\n",
      "Leaves — min: 2279 mean: 2814.8 max: 3400\n"
     ]
    }
   ],
   "source": [
    "rand_forest2 = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth = 20, ## max tree is 46 in exepriment 1, limiting this in 20\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced')\n",
    "\n",
    "rand_forest2.fit(X_train_encoded, y_train)\n",
    "rf_prob2 = rand_forest2.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = rand_forest2.predict(X_test_encoded)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, rf_prob2), 4))        \n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, rf_prob2), 4)) \n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "# depths of all trees\n",
    "depths = [est.tree_.max_depth for est in rand_forest2.estimators_]\n",
    "print(\"Tree depth — min:\", min(depths), \"mean:\", round(np.mean(depths), 2), \"max:\", max(depths))\n",
    "\n",
    "# number of leaves (optional)\n",
    "leaves = [est.get_n_leaves() for est in rand_forest2.estimators_]\n",
    "print(\"Leaves — min:\", min(leaves), \"mean:\", round(np.mean(leaves), 1), \"max:\", max(leaves))\n",
    "\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"rand_forest2\":{\n",
    "        \"prob\":rf_prob2,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e696950-0dff-4b86-a1a4-8b780dc7cc6c",
   "metadata": {},
   "source": [
    "**Random Forest Experiment 2 Notes:**\n",
    "- Precision stayed the same, with a very slight decrease. however the recall improved fopr the minority yes values. This led to an increase in the F1 score.\n",
    "- The ROC-AUC and the PR-AUC both essentially stayed the same with slight increases in performance\n",
    "- The min leaves were ~2300, should factor in for next run.\n",
    "- OVERALL: IMPROVEMENT ON RF 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c600a8-7290-4b8c-b9ea-fa6f752f582c",
   "metadata": {},
   "source": [
    "##### Experiment 3\n",
    "**GOAL:** Improve upon the baseline default settings, and that of the second experiment for Random Forest.Again, shifting the inputs in order to get a better result.  Increassing tree depth slightly, increasing the number of estimators with hopes of improving results. Additionally were increasing the number of minimum sampels needed for decining splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4841e3cc-8789-4bee-8e29-207a047f5bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92      7833\n",
      "           1       0.45      0.52      0.48      1051\n",
      "\n",
      "    accuracy                           0.87      8884\n",
      "   macro avg       0.69      0.72      0.70      8884\n",
      "weighted avg       0.88      0.87      0.87      8884\n",
      "\n",
      "Accuracy Score\n",
      "0.8681900045024764\n",
      "ROC-AUC : 0.8017\n",
      "PR-AUC  : 0.4422\n",
      "TP: 551 FP: 671 FN: 500 TN: 7162\n",
      "Tree depth — min: 25 mean: 25.0 max: 25\n",
      "Leaves — min: 1553 mean: 1744.1 max: 1937\n"
     ]
    }
   ],
   "source": [
    "rand_forest3 = RandomForestClassifier(\n",
    "    random_state=42,\n",
    "    max_depth = 25, ## max tree is 46 in exepriment 1, limiting this in 2\n",
    "    min_samples_split=20,\n",
    "    n_estimators=200, ## also increasing this from default\n",
    "    class_weight='balanced')\n",
    "rand_forest3.fit(X_train_encoded, y_train)\n",
    "rf_prob3 = rand_forest3.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = rand_forest3.predict(X_test_encoded)\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy Score\")\n",
    "print(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, rf_prob3), 4))        \n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, rf_prob3), 4)) \n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "# depths of all trees\n",
    "depths = [est.tree_.max_depth for est in rand_forest3.estimators_]\n",
    "print(\"Tree depth — min:\", min(depths), \"mean:\", round(np.mean(depths), 2), \"max:\", max(depths))\n",
    "\n",
    "# number of leaves (optional)\n",
    "leaves = [est.get_n_leaves() for est in rand_forest3.estimators_]\n",
    "print(\"Leaves — min:\", min(leaves), \"mean:\", round(np.mean(leaves), 1), \"max:\", max(leaves))\n",
    "\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"rand_forest3\":{\n",
    "        \"prob\":rf_prob3,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a49976c-4244-4421-9539-c982a98705c9",
   "metadata": {},
   "source": [
    "**Random Forest Experiment 3 Notes:**\n",
    "- Further refined the inputs based on the second experiment with random forest. This time allowed for more depth in the trees and increased the number of sampels taken for each node.Slso increased the n_estimators var. \n",
    "- This yeilded additional gains in recall but some slight decrease in precision for the yes values.\n",
    "- Very slight gains in the AUC values.\n",
    "- True positives incrased but so did false positives. True negs decreased while the false negs increased.\n",
    "- OVERALL: BETTER THAN RF 2. BEST SO FAR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab3c7a6-88f6-4313-b2b2-391d5bac640e",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "#### Experiment 1\n",
    "**GOAL:** Again getting a baseline for this modeling methodology at first. Default inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c273ce2f-766c-4992-b8d2-8157cd53347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AdaBoost Baseline (defaults) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.90      0.99      0.94      7833\n",
      "         yes       0.64      0.18      0.28      1051\n",
      "\n",
      "    accuracy                           0.89      8884\n",
      "   macro avg       0.77      0.58      0.61      8884\n",
      "weighted avg       0.87      0.89      0.86      8884\n",
      "\n",
      "ROC-AUC : 0.767\n",
      "PR-AUC  : 0.4153\n",
      "TP: 190 FP: 105 FN: 861 TN: 7728\n"
     ]
    }
   ],
   "source": [
    "## Runnin defaults \n",
    "ab1 = AdaBoostClassifier(random_state=42)   \n",
    "ab1.fit(X_train_encoded, y_train)\n",
    "ab1_proba = ab1.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = ab1.predict(X_test_encoded)\n",
    "\n",
    "\n",
    "print(\"=== AdaBoost Baseline (defaults) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['no','yes']))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, ab1_proba), 4))\n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, ab1_proba), 4))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"adaboost1\":{\n",
    "        \"prob\":ab1_proba,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1d48a1-505a-4490-a772-10176cafe759",
   "metadata": {},
   "source": [
    "**AdaBoost Experiment 1 Notes**\n",
    "- This method did the best for precision score on the first defa...ever, the recall values here are super low for the 'yes' values.\n",
    "- The ROC-AUC & PR-AUC is lower than the all of the random forest experiments\n",
    "- The confusiion matrix is unimpressive compared to all of the random forest experiments\n",
    "- OVERALL: WORSE THAN RF 3, CURRENT BEST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c74a2-28be-4581-bf2e-ac470c264680",
   "metadata": {},
   "source": [
    "#### Experiment 2\n",
    "**GOAL:** Adjusting the inputs to better tune the model to better results. Limiting depth of trees to 5 and increasing the learning rate by 50%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f135e53-421e-4890-8376-c9077fa7b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AdaBoost Baseline (defaults) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.97      0.94      7833\n",
      "         yes       0.54      0.28      0.37      1051\n",
      "\n",
      "    accuracy                           0.89      8884\n",
      "   macro avg       0.72      0.62      0.65      8884\n",
      "weighted avg       0.87      0.89      0.87      8884\n",
      "\n",
      "ROC-AUC : 0.7721\n",
      "PR-AUC  : 0.3874\n",
      "TP: 291 FP: 250 FN: 760 TN: 7583\n"
     ]
    }
   ],
   "source": [
    "## Runnin defaults \n",
    "tree_obj = DecisionTreeClassifier(max_depth=5, random_state=42) \n",
    "ab2 = AdaBoostClassifier(random_state=42,\n",
    "                        estimator= tree_obj ,\n",
    "                        n_estimators=100,\n",
    "                        learning_rate = 1.5)   \n",
    "ab2.fit(X_train_encoded, y_train)\n",
    "ab2_proba = ab2.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = ab2.predict(X_test_encoded)\n",
    "\n",
    "print(\"=== AdaBoost Baseline (defaults) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['no','yes']))\n",
    "\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, ab2_proba), 4))\n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, ab2_proba), 4))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"adaboost2\":{\n",
    "        \"prob\":ab2_proba,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd1cbe-bec0-4d0b-b636-ba58e97478c3",
   "metadata": {},
   "source": [
    "**AdaBoost Experiment 2 Notes**\n",
    "- Precision decreased for yes values when compared to experiment 1. The recall value for yes values did increase, yeilding a vbetter F1 score. \n",
    "- The PR- AUC decreased with these changes.\n",
    "  False positives increased a bit, however the true positive increase seems to out weigh this.\n",
    "- False negatives decreased compared to the first experiment.\n",
    "- OVERALL: WORSE THAN RF 3, CURRENTLY OVERALL BEST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af453a2a-f270-4de4-ae80-e562da58f156",
   "metadata": {},
   "source": [
    "#### Experiment 3\n",
    "**GOAL:** Again increasing the depth of trees a bit and the learning rate to see if this improves the model, as the second experiment's shifts were unimpressive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1058eff-8c79-4859-8a30-2ac1738fb31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AdaBoost Baseline (defaults) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.90      0.80      0.85      7833\n",
      "         yes       0.20      0.37      0.26      1051\n",
      "\n",
      "    accuracy                           0.75      8884\n",
      "   macro avg       0.55      0.58      0.55      8884\n",
      "weighted avg       0.82      0.75      0.78      8884\n",
      "\n",
      "ROC-AUC : 0.6406\n",
      "PR-AUC  : 0.2746\n",
      "TP: 389 FP: 1596 FN: 662 TN: 6237\n"
     ]
    }
   ],
   "source": [
    "## Runnin defaults \n",
    "tree_obj = DecisionTreeClassifier(max_depth=10, random_state=42) \n",
    "ab3 = AdaBoostClassifier(random_state=42,\n",
    "                        estimator= tree_obj ,\n",
    "                        n_estimators=100,\n",
    "                        learning_rate = 2)   \n",
    "ab3.fit(X_train_encoded, y_train)\n",
    "ab3_proba = ab3.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = ab3.predict(X_test_encoded)\n",
    "\n",
    "print(\"=== AdaBoost Baseline (defaults) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['no','yes']))\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, ab3_proba), 4))\n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, ab3_proba), 4))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"adaboost3\":{\n",
    "        \"prob\":ab3_proba,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad2cf99-2942-4285-a437-3d11c44edb0e",
   "metadata": {},
   "source": [
    "**AdaBoost Experiment 3 Notes**\n",
    "- True positives did increase, however, the False Positives increased drastically. The false negatvies decreased a bit.\n",
    "- PR-AUC decreased. Worse than the second experiment.\n",
    "- OVERALL: WORSE THAN RF 3 CURRENT BEST.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49592f7f-1972-4a47-aa5d-40489d8f3e4c",
   "metadata": {},
   "source": [
    "#### Experiment 4\n",
    "**GOAL:** Trying to better tune the model. I will keep the depth the same, however i will be lowering the learning rate and increasing the number of estimators in order to try and get better reuslts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6785bcba-33df-469b-84a1-af0479b27550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== AdaBoost Baseline (defaults) ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.90      0.98      0.94      7833\n",
      "         yes       0.56      0.23      0.33      1051\n",
      "\n",
      "    accuracy                           0.89      8884\n",
      "   macro avg       0.73      0.60      0.63      8884\n",
      "weighted avg       0.86      0.89      0.87      8884\n",
      "\n",
      "ROC-AUC : 0.7636\n",
      "PR-AUC  : 0.3879\n",
      "TP: 242 FP: 191 FN: 809 TN: 7642\n"
     ]
    }
   ],
   "source": [
    "## Runnin defaults \n",
    "tree_obj = DecisionTreeClassifier(max_depth=10, random_state=42) \n",
    "ab4 = AdaBoostClassifier(random_state=42,\n",
    "                        estimator= tree_obj ,\n",
    "                        n_estimators=300,\n",
    "                        learning_rate = 1.25)   \n",
    "ab4.fit(X_train_encoded, y_train)\n",
    "ab4_proba = ab4.predict_proba(X_test_encoded)[:, 1]\n",
    "y_pred = ab4.predict(X_test_encoded)\n",
    "\n",
    "print(\"=== AdaBoost Baseline (defaults) ===\")\n",
    "print(classification_report(y_test, y_pred, target_names=['no','yes']))\n",
    "print(\"ROC-AUC :\", round(metrics.roc_auc_score(y_test, ab4_proba), 4))\n",
    "print(\"PR-AUC  :\", round(metrics.average_precision_score(y_test, ab4_proba), 4))\n",
    "\n",
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"TP:\", tp, \"FP:\", fp, \"FN:\", fn, \"TN:\", tn)\n",
    "\n",
    "## Adding to the dict \n",
    "running_results.update(\n",
    "    {\"adaboost4\":{\n",
    "        \"prob\":ab4_proba,\n",
    "        \"y_pred\":y_pred,       \n",
    "    }\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4983ae-e67e-4bd1-a37c-8a739e5c787e",
   "metadata": {},
   "source": [
    "**AdaBoost Experiment 4 Notes**\n",
    "- False Negatives increaed. True Posuitives decreased. \n",
    "- PR-AUC increased from Experiment 3, as did ROC-AUC. \n",
    "- Precison increased a decent amount, but recal fell.\n",
    "- OVERALL: WORSE THAN RF 3, CURRENT BEST. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326de0c-a542-441f-beda-0cf3d58eefc9",
   "metadata": {},
   "source": [
    "### RESULTS WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c39488c-f7a8-4a50-ad83-6112a96f3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "\n",
    "for model_name, vals in running_results.items():\n",
    "    prob = np.array(vals[\"prob\"])\n",
    "    y_pred = np.array(vals[\"y_pred\"]).ravel()\n",
    "    if prob.ndim == 2 and prob.shape[1] == 2:\n",
    "        prob = prob[:, 1]\n",
    "    else:\n",
    "        prob = prob.ravel()\n",
    "    classfctn_rpt = classification_report(y_test, y_pred, target_names=['no','yes'],output_dict=True)\n",
    "    roc_auc = round(metrics.roc_auc_score(y_test, prob), 4)\n",
    "    pr_auc = round(metrics.average_precision_score(y_test, prob), 4)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": model_name,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"precision_pos\": classfctn_rpt[\"yes\"][\"precision\"],\n",
    "        \"recall_pos\": classfctn_rpt[\"yes\"][\"recall\"],\n",
    "        \"f1_pos\": classfctn_rpt[\"yes\"][\"f1-score\"],\n",
    "        \"precision_neg\": classfctn_rpt[\"no\"][\"precision\"],\n",
    "        \"recall_neg\": classfctn_rpt[\"no\"][\"recall\"],\n",
    "        \"f1_neg\": classfctn_rpt[\"no\"][\"f1-score\"],\n",
    "        \"macro_precision\": classfctn_rpt[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\": classfctn_rpt[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\": classfctn_rpt[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": classfctn_rpt[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\": classfctn_rpt[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\": classfctn_rpt[\"weighted avg\"][\"f1-score\"],\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(rows).set_index(\"model\").round(4)\n",
    "results_df  = results_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d69641a-139d-42e5-a672-5c3303ba306d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>precision_pos</th>\n",
       "      <th>recall_pos</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>precision_neg</th>\n",
       "      <th>recall_neg</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rand_forest3</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4509</td>\n",
       "      <td>0.5243</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>7162</td>\n",
       "      <td>671</td>\n",
       "      <td>500</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rand_forest2</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>7393</td>\n",
       "      <td>440</td>\n",
       "      <td>616</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rand_forest1</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.8701</td>\n",
       "      <td>7665</td>\n",
       "      <td>168</td>\n",
       "      <td>798</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adaboost1</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>7728</td>\n",
       "      <td>105</td>\n",
       "      <td>861</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dec_tree2</td>\n",
       "      <td>0.7744</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.8513</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.6664</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>6668</td>\n",
       "      <td>1165</td>\n",
       "      <td>427</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adaboost4</td>\n",
       "      <td>0.7636</td>\n",
       "      <td>0.3879</td>\n",
       "      <td>0.5589</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.3261</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>0.7316</td>\n",
       "      <td>0.6029</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.8634</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8661</td>\n",
       "      <td>7642</td>\n",
       "      <td>191</td>\n",
       "      <td>809</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adaboost2</td>\n",
       "      <td>0.7721</td>\n",
       "      <td>0.3874</td>\n",
       "      <td>0.5379</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.3656</td>\n",
       "      <td>0.9089</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.7234</td>\n",
       "      <td>0.6225</td>\n",
       "      <td>0.6516</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>7583</td>\n",
       "      <td>250</td>\n",
       "      <td>760</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adaboost3</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.2746</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.3701</td>\n",
       "      <td>0.2563</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>0.5500</td>\n",
       "      <td>0.5832</td>\n",
       "      <td>0.5515</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.7458</td>\n",
       "      <td>0.7769</td>\n",
       "      <td>6237</td>\n",
       "      <td>1596</td>\n",
       "      <td>662</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dec_tree1</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.1746</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.3302</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.5986</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.6039</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>0.8296</td>\n",
       "      <td>6979</td>\n",
       "      <td>854</td>\n",
       "      <td>704</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  roc_auc  pr_auc  precision_pos  recall_pos  f1_pos  \\\n",
       "4  rand_forest3   0.8017  0.4422         0.4509      0.5243  0.4848   \n",
       "3  rand_forest2   0.7958  0.4350         0.4971      0.4139  0.4517   \n",
       "2  rand_forest1   0.7861  0.4239         0.6010      0.2407  0.3438   \n",
       "5     adaboost1   0.7670  0.4153         0.6441      0.1808  0.2823   \n",
       "1     dec_tree2   0.7744  0.4040         0.3488      0.5937  0.4394   \n",
       "8     adaboost4   0.7636  0.3879         0.5589      0.2303  0.3261   \n",
       "6     adaboost2   0.7721  0.3874         0.5379      0.2769  0.3656   \n",
       "7     adaboost3   0.6406  0.2746         0.1960      0.3701  0.2563   \n",
       "0     dec_tree1   0.6106  0.1746         0.2889      0.3302  0.3082   \n",
       "\n",
       "   precision_neg  recall_neg  f1_neg  macro_precision  macro_recall  macro_f1  \\\n",
       "4         0.9347      0.9143  0.9244           0.6928        0.7193    0.7046   \n",
       "3         0.9231      0.9438  0.9333           0.7101        0.6789    0.6925   \n",
       "2         0.9057      0.9786  0.9407           0.7533        0.6096    0.6422   \n",
       "5         0.8998      0.9866  0.9412           0.7719        0.5837    0.6117   \n",
       "1         0.9398      0.8513  0.8934           0.6443        0.7225    0.6664   \n",
       "8         0.9043      0.9756  0.9386           0.7316        0.6029    0.6324   \n",
       "6         0.9089      0.9681  0.9376           0.7234        0.6225    0.6516   \n",
       "7         0.9040      0.7962  0.8467           0.5500        0.5832    0.5515   \n",
       "0         0.9084      0.8910  0.8996           0.5986        0.6106    0.6039   \n",
       "\n",
       "   weighted_precision  weighted_recall  weighted_f1    tn    fp   fn   tp  \n",
       "4              0.8775           0.8682       0.8724  7162   671  500  551  \n",
       "3              0.8727           0.8811       0.8764  7393   440  616  435  \n",
       "2              0.8697           0.8913       0.8701  7665   168  798  253  \n",
       "5              0.8695           0.8913       0.8632  7728   105  861  190  \n",
       "1              0.8699           0.8208       0.8397  6668  1165  427  624  \n",
       "8              0.8634           0.8874       0.8661  7642   191  809  242  \n",
       "6              0.8650           0.8863       0.8699  7583   250  760  291  \n",
       "7              0.8203           0.7458       0.7769  6237  1596  662  389  \n",
       "0              0.8351           0.8246       0.8296  6979   854  704  347  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by =[\"pr_auc\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e36aa5c5-9673-4b8f-8eda-166c757191d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df[['model', 'pr_auc','recall_pos','precision_pos','f1_pos','fn','roc_auc']][results_df[\"model\"].astype(str).str.contains(\"ada\")].sort_values(by =[\"model\"], ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c1354e5-b001-45f2-b774-93bbcf9e6108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>precision_pos</th>\n",
       "      <th>recall_pos</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>precision_neg</th>\n",
       "      <th>recall_neg</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rand_forest3</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4509</td>\n",
       "      <td>0.5243</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>7162</td>\n",
       "      <td>671</td>\n",
       "      <td>500</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rand_forest2</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>7393</td>\n",
       "      <td>440</td>\n",
       "      <td>616</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rand_forest1</td>\n",
       "      <td>0.7861</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>0.6010</td>\n",
       "      <td>0.2407</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9786</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.7533</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>0.6422</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.8701</td>\n",
       "      <td>7665</td>\n",
       "      <td>168</td>\n",
       "      <td>798</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  roc_auc  pr_auc  precision_pos  recall_pos  f1_pos  \\\n",
       "4  rand_forest3   0.8017  0.4422         0.4509      0.5243  0.4848   \n",
       "3  rand_forest2   0.7958  0.4350         0.4971      0.4139  0.4517   \n",
       "2  rand_forest1   0.7861  0.4239         0.6010      0.2407  0.3438   \n",
       "\n",
       "   precision_neg  recall_neg  f1_neg  macro_precision  macro_recall  macro_f1  \\\n",
       "4         0.9347      0.9143  0.9244           0.6928        0.7193    0.7046   \n",
       "3         0.9231      0.9438  0.9333           0.7101        0.6789    0.6925   \n",
       "2         0.9057      0.9786  0.9407           0.7533        0.6096    0.6422   \n",
       "\n",
       "   weighted_precision  weighted_recall  weighted_f1    tn   fp   fn   tp  \n",
       "4              0.8775           0.8682       0.8724  7162  671  500  551  \n",
       "3              0.8727           0.8811       0.8764  7393  440  616  435  \n",
       "2              0.8697           0.8913       0.8701  7665  168  798  253  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### From this DF im taking my tiop 3 models based on my chosen metrics (PR-AUC) and False negatives. \n",
    "top_3 = results_df.sort_values(by =[\"pr_auc\"], ascending=False)[:3]\n",
    "top_3\n",
    "\n",
    "# The top 3 models were all the random forest models. Based on the pr_auc score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c3029c5-47cc-4581-ba8c-9c5e61537140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>precision_pos</th>\n",
       "      <th>recall_pos</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>precision_neg</th>\n",
       "      <th>recall_neg</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rand_forest3</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4509</td>\n",
       "      <td>0.5243</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>7162</td>\n",
       "      <td>671</td>\n",
       "      <td>500</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dec_tree2</td>\n",
       "      <td>0.7744</td>\n",
       "      <td>0.4040</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>0.5937</td>\n",
       "      <td>0.4394</td>\n",
       "      <td>0.9398</td>\n",
       "      <td>0.8513</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.6443</td>\n",
       "      <td>0.7225</td>\n",
       "      <td>0.6664</td>\n",
       "      <td>0.8699</td>\n",
       "      <td>0.8208</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>6668</td>\n",
       "      <td>1165</td>\n",
       "      <td>427</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adaboost1</td>\n",
       "      <td>0.7670</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.9412</td>\n",
       "      <td>0.7719</td>\n",
       "      <td>0.5837</td>\n",
       "      <td>0.6117</td>\n",
       "      <td>0.8695</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.8632</td>\n",
       "      <td>7728</td>\n",
       "      <td>105</td>\n",
       "      <td>861</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  roc_auc  pr_auc  precision_pos  recall_pos  f1_pos  \\\n",
       "4  rand_forest3   0.8017  0.4422         0.4509      0.5243  0.4848   \n",
       "1     dec_tree2   0.7744  0.4040         0.3488      0.5937  0.4394   \n",
       "5     adaboost1   0.7670  0.4153         0.6441      0.1808  0.2823   \n",
       "\n",
       "   precision_neg  recall_neg  f1_neg  macro_precision  macro_recall  macro_f1  \\\n",
       "4         0.9347      0.9143  0.9244           0.6928        0.7193    0.7046   \n",
       "1         0.9398      0.8513  0.8934           0.6443        0.7225    0.6664   \n",
       "5         0.8998      0.9866  0.9412           0.7719        0.5837    0.6117   \n",
       "\n",
       "   weighted_precision  weighted_recall  weighted_f1    tn    fp   fn   tp  \n",
       "4              0.8775           0.8682       0.8724  7162   671  500  551  \n",
       "1              0.8699           0.8208       0.8397  6668  1165  427  624  \n",
       "5              0.8695           0.8913       0.8632  7728   105  861  190  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### If looking at the best model per category, \n",
    "best_dt  = results_df[results_df['model'].str.startswith('dec_tree')].sort_values('pr_auc', ascending=False).iloc[[0]]\n",
    "best_rf  = results_df[results_df['model'].str.startswith('rand_forest')].sort_values('pr_auc', ascending=False).iloc[[0]]\n",
    "best_ab  = results_df[results_df['model'].str.startswith('adaboost')].sort_values('pr_auc', ascending=False).iloc[[0]]\n",
    "\n",
    "best_of_each = pd.concat([best_rf,best_dt,best_ab])\n",
    "best_of_each\n",
    "## The third random forest experiemtn was the best,  the first adaboost model was the best, and the second decision tree experiment was the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed4b1b-8cdf-4164-8043-608cac14d692",
   "metadata": {},
   "source": [
    "## Overall Best MOdel was the Third Experiement for Random Forest Methodology. It scores thebest for the PR-AUC. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

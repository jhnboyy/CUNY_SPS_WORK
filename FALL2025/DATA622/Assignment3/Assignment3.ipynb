{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561ea326-0a74-41e6-b399-9bac2e054cb7",
   "metadata": {},
   "source": [
    "## Assignment 3 \n",
    "\n",
    "#### Instructions\n",
    "Perform an analysis of the dataset(s) used in Homework #2 using the SVM algorithm. Compare the results with the results from previous homework.\n",
    "Homework #3\n",
    "\n",
    "- Read the following articles:\n",
    "    - https://www.hindawi.com/journals/complexity/2021/5550344/\n",
    "    - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8137961/\n",
    "- Search for academic content (at least 3 articles) that compare the use of decision trees vs SVMs in your current area of expertise.\n",
    "- Perform an analysis of the dataset used in Homework #2 using the SVM algorithm.\n",
    "- Compare the results with the results from previous homework.\n",
    "- Answer questions, such as:\n",
    "  - Which algorithm is recommended to get more accurate results?\n",
    "  - Is it better for classification or regression scenarios?\n",
    "  - Do you agree with the recommendations?\n",
    "  - Why?\n",
    "\n",
    "#### Format\n",
    " - Essay (minimum 500 word document) Write a short essay explaining your selection of algorithms and how they relate to the data and what you are trying to do.\n",
    " - Analysis using R or Python (submit code + errors + analysis as notebook or copy/paste to document).Include analysis R (or Python) code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa44f48-4de9-4b8a-a1e8-52296ba7f45b",
   "metadata": {},
   "source": [
    "### Two Assigned Articles "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f14fb5-bc39-4ade-b30b-4c710b9bd51d",
   "metadata": {},
   "source": [
    "##### Decision Tree Ensembles to Predict Coronavirus Disease 2019 Infection: A Comparative Study (https://www.hindawi.com/journals/complexity/2021/5550344/)\n",
    "\n",
    "- This paper looked at COvid-19 in patients and attempted to use decision tree modeling on lab results and patient age, with imbalanced outcome considerations, for properly predicting COVID diagnosis in patients. There were 5644 total patients in the original data, with 600 final patients being kept in the study using about 18 different lab biomarker measurements. Of the 600 patents used, 520 were negative and 80 were positive. So about a 13% positivity rate. Data was imbalanced so RUS and SMOTE were used, and the multiple types of Classifier methods were used to obtain results. Overall the best modeling technique was random forest having highest accuracy. with RUSBagging, Balanced Random ForestBalanced, and XGBoost with RUS doing well too.\n",
    "\n",
    "##### A novel approach to predict COVID-19 using support vector machine (https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8137961/)\n",
    "\n",
    "- This paper predicts COVID-19 status using a support vector machine modeling on individual's symptoms. The dataset was composrted of 200 individual's data with 8 different symtopms\": temperature, breathing rate, hypertension, stage heart beat rate, acute respiratory distress syndrome, chest pain, heart disease and cough with sputum. The modeling attempted to categorize inidivduals into three differewnt classes: not infected, mildly infected, and severely infected. They used a linear SVM model and a 70/30 training/test split. THe modeling yielded The modeling yielded an overall accuracy of 87 percent, with class results showing the severely infected class with a precision  of 0.94, recall of 1.00, and f1 of 0.97. The the not infected and mildly infected classes were lower. SVM performed best on this dataset when compared to k-nearest neighbors,naive Bayes, random forest, and AdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db6cdda-6fe0-4739-a0bb-974c7b4fd2b5",
   "metadata": {},
   "source": [
    "### Three Acadmic Researched Articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0707d58c-8dbb-42fa-8cb3-50c14d7ef767",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1) A comparative study of forecasting corporate credit ratings using neural networks, support vector machines, and decision trees \n",
    "\n",
    "##### 2) \n",
    "##### 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a101237-b735-4212-9569-965d69921970",
   "metadata": {},
   "source": [
    "### Performing SVM on Assignment 2 Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21541d61-0c24-4909-a5c4-4db816e8f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import (average_precision_score, roc_auc_score,\n",
    "                             classification_report, confusion_matrix,\n",
    "                             PrecisionRecallDisplay)\n",
    "from sklearn.preprocessing import StandardScaler "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474f16c-699a-4b6d-972b-ef46869cb1d1",
   "metadata": {},
   "source": [
    "#### Assignment 2 Replication for the SVM training and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40780b4e-a6f1-41e1-9c9e-83621b70f742",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pulling in the data from Assignment 1 \n",
    "df = pd.read_csv(\"../Assignment2/raw_df_dropped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef9cc467-1cc4-4d9f-9367-caf81ac9653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'job', 'marital', 'education', 'default', 'balance', 'housing',\n",
      "       'loan', 'contact', 'day_of_week', 'month', 'campaign', 'previous',\n",
      "       'poutcome', 'y', 'previously_contacted'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns) # No duration because dropped in assignment one. (Data Leakage) \n",
    "\n",
    "## Encoding the y var for (1/0) | (yes/no)\n",
    "df['y'] = df['y'].map({'no':0, 'yes':1})\n",
    "\n",
    "## Parsing the 'y' from the x vars \n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "## Splitting the test and train sets for future experiments and modeling\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Confirming no nulls; no additional imputation needed because of Assignment 1 cleaning etc. \n",
    "# print(X_train.info())\n",
    "# print(y_train.info())\n",
    "# print(X_test.info())\n",
    "# print(y_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53049ff3-4f9b-45b4-84e6-2f1725cdfc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'balance', 'day_of_week', 'campaign', 'previous']\n",
      "['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome', 'previously_contacted']\n"
     ]
    }
   ],
   "source": [
    "# Getting lists of the x vars and their types For encoding pre-modeling \n",
    "num_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
    "print(num_cols)\n",
    "cat_cols = [c for c in X_train.columns if c not in num_cols]\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f962bd06-e560-4663-bb23-b2ac57b664ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_encoded = pd.get_dummies(X_train, columns=cat_cols, drop_first=False)\n",
    "X_test_encoded  = pd.get_dummies(X_test,  columns=cat_cols, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a979924-37d1-49b2-ab32-7a091f8f255b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in X_train_encoded.columns if i not in X_test_encoded.columns])\n",
    "print([i for i in X_test_encoded.columns if i not in X_train_encoded.columns])\n",
    "## Columns are identical, no missing categories in each df so no need for alignment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0decb8b9-96d1-4507-88c1-945f20045e61",
   "metadata": {},
   "source": [
    "#### End Assignment Two Replica Code. Beginning of Assignment 3 Changes for SVM modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b717cb2-93e8-4bcb-900a-24d97b7d3924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>35536.0</td>\n",
       "      <td>-2.975258e-16</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.149123</td>\n",
       "      <td>-0.738651</td>\n",
       "      <td>-0.174462</td>\n",
       "      <td>0.671821</td>\n",
       "      <td>5.091300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>35536.0</td>\n",
       "      <td>1.829544e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-2.664600</td>\n",
       "      <td>-0.417440</td>\n",
       "      <td>-0.295665</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>32.722977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day_of_week</th>\n",
       "      <td>35536.0</td>\n",
       "      <td>-4.618848e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-1.776109</td>\n",
       "      <td>-0.935933</td>\n",
       "      <td>0.024268</td>\n",
       "      <td>0.624393</td>\n",
       "      <td>1.824645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign</th>\n",
       "      <td>35536.0</td>\n",
       "      <td>7.058239e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-0.571367</td>\n",
       "      <td>-0.571367</td>\n",
       "      <td>-0.244724</td>\n",
       "      <td>0.081918</td>\n",
       "      <td>18.047243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>35536.0</td>\n",
       "      <td>-3.739067e-17</td>\n",
       "      <td>1.000014</td>\n",
       "      <td>-0.245294</td>\n",
       "      <td>-0.245294</td>\n",
       "      <td>-0.245294</td>\n",
       "      <td>-0.245294</td>\n",
       "      <td>113.211503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count          mean       std       min       25%       50%  \\\n",
       "age          35536.0 -2.975258e-16  1.000014 -2.149123 -0.738651 -0.174462   \n",
       "balance      35536.0  1.829544e-17  1.000014 -2.664600 -0.417440 -0.295665   \n",
       "day_of_week  35536.0 -4.618848e-17  1.000014 -1.776109 -0.935933  0.024268   \n",
       "campaign     35536.0  7.058239e-17  1.000014 -0.571367 -0.571367 -0.244724   \n",
       "previous     35536.0 -3.739067e-17  1.000014 -0.245294 -0.245294 -0.245294   \n",
       "\n",
       "                  75%         max  \n",
       "age          0.671821    5.091300  \n",
       "balance      0.018353   32.722977  \n",
       "day_of_week  0.624393    1.824645  \n",
       "campaign     0.081918   18.047243  \n",
       "previous    -0.245294  113.211503  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Scaling the numeric data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train_encoded.copy()\n",
    "X_test_scaled  = X_test_encoded.copy()\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train_encoded[num_cols])\n",
    "X_test_scaled[num_cols]  = scaler.transform(X_test_encoded[num_cols])\n",
    "\n",
    "##  looking  at scaled vals sample \n",
    "X_train_scaled[num_cols].describe().T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0db7d30-51a9-479d-81af-83830327365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepping Result Holding Vals\n",
    "THRESH = 0.5\n",
    "running_results = {}\n",
    "rows = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "575907ae-e32b-41ed-a6b8-9ba60a97f1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the first linar SVM model\n",
    "lin_base = LinearSVC(class_weight=\"balanced\", random_state=42)\n",
    "lin_cal  = CalibratedClassifierCV(lin_base, method=\"sigmoid\", cv=5)\n",
    "\n",
    "#Fitting the model\n",
    "lin_cal.fit(X_train_scaled, y_train)\n",
    "\n",
    "## Predicting values\n",
    "lin_probs = lin_cal.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "## adding results to the running dict.\n",
    "lin_y_pred = (lin_probs >= THRESH).astype(int)\n",
    "\n",
    "# what C did you use for LinearSVC? (default is 1.0 if you didn't set it)\n",
    "lin_C = getattr(lin_base, \"C\", 1.0)\n",
    "lin_params = {\"C\": lin_C,   \"gamma\": \"N/A\"}\n",
    "\n",
    "running_results[\"svm_linear_cal\"] = {\"prob\": lin_probs, \"y_pred\": lin_y_pred, \"params\": lin_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209b85e-f91d-46f9-abd7-d0694dbae5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_rbf_C0.1_gscale\n",
      "svm_rbf_C0.1_g0.1\n",
      "svm_rbf_C0.1_g0.06\n",
      "svm_rbf_C0.1_g0.04\n",
      "svm_rbf_C0.1_g0.03\n",
      "svm_rbf_C0.1_g0.02\n"
     ]
    }
   ],
   "source": [
    "## RBF SVM : curved boiundaries, imbalanced y values \n",
    "rbf = SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=True, random_state=42)\n",
    "\n",
    "## Trying different settings for liencncy and finding neighbors\n",
    "param_grid = {\n",
    "    \"C\":     [0.1, 0.25, 0.75, 1, 2, 3, 5, 10],\n",
    "    \"gamma\": [\"scale\", 0.1, 0.06, 0.04, 0.03, 0.02, 0.01]\n",
    "}\n",
    "\n",
    "for params in ParameterGrid(param_grid):\n",
    "    C = params[\"C\"]; gamma = params[\"gamma\"]\n",
    "    key = f\"svm_rbf_C{C}_g{gamma}\"\n",
    "    \n",
    "    print(key)\n",
    "    # 1) fit this combo\n",
    "    clf = SVC(kernel=\"rbf\", class_weight=\"balanced\", probability=True,\n",
    "              random_state=42, C=C, gamma=gamma)\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # 2) test predictions\n",
    "    probs = clf.predict_proba(X_test_scaled)[:, 1]\n",
    "    y_pred = (probs >= THRESH).astype(int)\n",
    "\n",
    "    # 3) store minimal artifacts (probabilities + hard preds) -> for your later aggregation\n",
    "    running_results[key] = {\"prob\": probs, \"y_pred\": y_pred, \"params\": params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17195a8f-7f38-42c0-847b-3af83b76c35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the Results Metrics to the Rows Lists via Running Results DIct\n",
    "for key, value in running_results.items():\n",
    "    \n",
    "    print(key)\n",
    "    model_prob = value[\"prob\"]\n",
    "    y_pred = value[\"y_pred\"]\n",
    "    params = value[\"params\"]\n",
    "    C = params[\"C\"]\n",
    "    gamma = params[\"gamma\"]\n",
    "    \n",
    "    classfctn_rpt = classification_report( y_test, y_pred, target_names=['no','yes'], output_dict=True )\n",
    "    \n",
    "    roc_auc = round(metrics.roc_auc_score(y_test, model_prob), 4)\n",
    "    pr_auc  = round(metrics.average_precision_score(y_test, model_prob), 4)\n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": key,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"pr_auc\": pr_auc,\n",
    "        \"precision_pos\": classfctn_rpt[\"yes\"][\"precision\"],\n",
    "        \"recall_pos\":    classfctn_rpt[\"yes\"][\"recall\"],\n",
    "        \"f1_pos\":        classfctn_rpt[\"yes\"][\"f1-score\"],\n",
    "        \"precision_neg\": classfctn_rpt[\"no\"][\"precision\"],\n",
    "        \"recall_neg\":    classfctn_rpt[\"no\"][\"recall\"],\n",
    "        \"f1_neg\":        classfctn_rpt[\"no\"][\"f1-score\"],\n",
    "        \"macro_precision\":   classfctn_rpt[\"macro avg\"][\"precision\"],\n",
    "        \"macro_recall\":      classfctn_rpt[\"macro avg\"][\"recall\"],\n",
    "        \"macro_f1\":          classfctn_rpt[\"macro avg\"][\"f1-score\"],\n",
    "        \"weighted_precision\": classfctn_rpt[\"weighted avg\"][\"precision\"],\n",
    "        \"weighted_recall\":    classfctn_rpt[\"weighted avg\"][\"recall\"],\n",
    "        \"weighted_f1\":        classfctn_rpt[\"weighted avg\"][\"f1-score\"],\n",
    "        \"tn\": tn, \"fp\": fp, \"fn\": fn, \"tp\": tp,\n",
    "        \"C\": C, \"gamma\": gamma\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2192d76-93b4-4c92-9489-9c70435a5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All SVM results \n",
    "svm_results =  pd.DataFrame(rows).round(4)\n",
    "svm_results['Assignment']=\"Assignment 3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1ef57-9e11-45a6-9775-8e2cb8df065e",
   "metadata": {},
   "source": [
    "#### Pulling in Top Performing models from Assignment 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f3a901-a1bd-43c2-9133-ed069237bc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>precision_pos</th>\n",
       "      <th>recall_pos</th>\n",
       "      <th>f1_pos</th>\n",
       "      <th>precision_neg</th>\n",
       "      <th>recall_neg</th>\n",
       "      <th>f1_neg</th>\n",
       "      <th>macro_precision</th>\n",
       "      <th>macro_recall</th>\n",
       "      <th>macro_f1</th>\n",
       "      <th>weighted_precision</th>\n",
       "      <th>weighted_recall</th>\n",
       "      <th>weighted_f1</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_forest3</td>\n",
       "      <td>0.8017</td>\n",
       "      <td>0.4422</td>\n",
       "      <td>0.4509</td>\n",
       "      <td>0.5243</td>\n",
       "      <td>0.4848</td>\n",
       "      <td>0.9347</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>0.7046</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>7162</td>\n",
       "      <td>671</td>\n",
       "      <td>500</td>\n",
       "      <td>551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rand_forest2</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>0.4350</td>\n",
       "      <td>0.4971</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9333</td>\n",
       "      <td>0.7101</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>0.8764</td>\n",
       "      <td>7393</td>\n",
       "      <td>440</td>\n",
       "      <td>616</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adaboost1</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>0.4289</td>\n",
       "      <td>0.6285</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>0.9410</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>0.5889</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>0.8687</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>7713</td>\n",
       "      <td>120</td>\n",
       "      <td>848</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model  roc_auc  pr_auc  precision_pos  recall_pos  f1_pos  \\\n",
       "0  rand_forest3   0.8017  0.4422         0.4509      0.5243  0.4848   \n",
       "1  rand_forest2   0.7958  0.4350         0.4971      0.4139  0.4517   \n",
       "2     adaboost1   0.7851  0.4289         0.6285      0.1931  0.2955   \n",
       "\n",
       "   precision_neg  recall_neg  f1_neg  macro_precision  macro_recall  macro_f1  \\\n",
       "0         0.9347      0.9143  0.9244           0.6928        0.7193    0.7046   \n",
       "1         0.9231      0.9438  0.9333           0.7101        0.6789    0.6925   \n",
       "2         0.9009      0.9847  0.9410           0.7647        0.5889    0.6182   \n",
       "\n",
       "   weighted_precision  weighted_recall  weighted_f1    tn   fp   fn   tp  \n",
       "0              0.8775           0.8682       0.8724  7162  671  500  551  \n",
       "1              0.8727           0.8811       0.8764  7393  440  616  435  \n",
       "2              0.8687           0.8910       0.8646  7713  120  848  203  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assgn2_best = pd.read_csv(\"../Assignment2/Assignment2_top3_model_results.csv\")\n",
    "assgn2_best['Assignment']=\"Assignment 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1de006-f959-40ad-9052-d5b4f9e7a542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "171a5da5-bcb3-4078-a882-b2d90e8a05f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81b0eea-36c2-4466-a379-6a75e9e22ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004af2d-5f99-46e0-999c-4d75e0c5a8a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb8d9e3-b0d9-4a38-9017-f1b74150972a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249fcbdb-37c8-426b-bf76-acd9545d882e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b304b-b1fd-4044-b093-8ca1696633c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f81ef9-6576-49ce-9112-3ec67f945a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f007a9-e860-441e-ab5c-ec30306bf037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
